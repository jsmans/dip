\documentclass{book}

\input{../definitions}

\usepackage{tikz}
\usetikzlibrary{fit,shapes.geometric}

\newcommand\marktopleft[1]{%
    \tikz[overlay,remember picture] 
        \node (marker-#1-a) at (0,1.5ex) {};%
}
\newcommand\markbottomright[1]{%
    \tikz[overlay,remember picture] 
        \node (marker-#1-b) at (0,0) {};%
    \tikz[overlay,remember picture,thick,dashed,inner sep=3pt]
        \node[draw,rounded rectangle,fit=(marker-#1-a.center) (marker-#1-b.center)] {};%
}
\newcounter{nodemarkers}
\newcommand\circletext[1]{%
    \tikz[overlay,remember picture] 
        \node (marker-\arabic{nodemarkers}-a) at (0,1.5ex) {};%
    #1%
    \tikz[overlay,remember picture]
        \node (marker-\arabic{nodemarkers}-b) at (0,0){};%
    \tikz[overlay,remember picture,inner sep=2pt]
        \node[draw,ellipse,fit=(marker-\arabic{nodemarkers}-a.center) (marker-\arabic{nodemarkers}-b.center)] {};%
    \stepcounter{nodemarkers}%
}

\setcounter{MaxMatrixCols}{11}


\begin{document}

\addtocounter{chapter}{4}

\chapter{Neighborhood Operations}
A neighborhood operation is an image processing step that takes an image as input and that computes a new value for each pixel based on its neighorhood. That is, the color of each pixel in the output image does not only depend on the color of the corresponding pixel in the input image but also on the colors of nearby pixels in the input image.

Setting each pixel in the image to the maximum color occurring in the pixel's neighborhood is a simple neighborhood operation. Applying this operation to the image matrix shown below on the left results in the image matrix shown on the right.

\renewcommand\arraystretch{1.6}
\begin{minipage}[b]{0.4\linewidth}\centering
\begin{tabular}{| c | c | c | c | c | c |}
\hline
4 & 68 & 32 & 11 & 4 & 58\\
\hline
49 & 19\cellcolor{yellow} & 58\cellcolor{yellow} & 53\cellcolor{yellow} & 82 & 1\\
\hline
0 & 13\cellcolor{yellow} &  \circletext{\textcolor{red}{37}}\cellcolor{yellow} & 34\cellcolor{yellow} & 29 & 76\\
\hline
45 & 3\cellcolor{yellow} & 51\cellcolor{yellow} & 64\cellcolor{yellow} & 87 & 47\\
\hline
12 & 83 & 92 & 54 & 65 & 67\\
\hline
32 & 39 & 71 & 94 & 73 & 5\\
\hline
\end{tabular}
\end{minipage}
\begin{minipage}[b]{0.5\linewidth}\centering
\begin{tabular}{| c | c | c | c | c | c |}
\hline
68 & 68 & 68 & 82 & 82 & 82\\
\hline
68 & 68 & 68 & 82 & 82 & 82\\
\hline
45 & 58 &  \circletext{\textcolor{red}{64}} & 87 & 87 & 87\\
\hline
83 & 92 & 92 & 92 & 87 & 87\\
\hline
83 & 94 & 94 & ? & 87 & 87\\
\hline
83 & 94 & 94 & 94 & 73 & 73\\
\hline
\end{tabular}
\end{minipage}

For example, the new color of the pixel at coordinate $(2, 2)$ is $64$, because $64$ is the maximum color in the 3 by 3 area around the pixel in the input image (i.e. the maximum of $19$, $58$, $53$, $13$, $37$, $34$, $3$, $51$, $64$). That is, the new color of the pixel at coordinate $(2, 2)$ depends only on pixels highlighted in yellow in the input image.

\begin{exercise}
What is the new color of the pixel at coordinate $(3, 4)$? Which input pixels influence this color?
\end{exercise}

\section{A Tiny Framework for Neighborhood Operations}
Each neighborhood operation computes a new value for each pixel based on the pixel itself and its neighborhood. To model the common aspects shared by all neighborhood operations, we define an abstract class \co{NeighborhoodOperation}:
\begin{lstlisting}
public abstract class NeighborhoodOperation {

  public abstract int neighborhoodFunction(ImageProcessor ip, int x, int y);

  public void applyTo(ImageProcessor ip) {
    ImageProcessor copy = ip.duplicate();
    for(int x = 0; x < ip.getWidth(); x++) {
      for(int y = 0; y < ip.getHeight(); y++) {
        int newColor = neighborhoodFunction(copy, x, y);
        ip.putPixel(x, y, newColor);     
      }    
    }  
  }
}
\end{lstlisting}
The template method \co{applyTo} assigns a new color to each pixel. The new color of each pixel is a function of the pixel's neighborhood and is computed by method \co{neighborhoodFunction}.  Specific neighborhood operations are modelled as subclasses of \co{NeighborhoodOperation}. In particular, subclasses must override the abstract method \co{neighborhoodFunction}. Let's look at an example. Replacing each pixel with the maximum color occurring in the pixel's neighborhood is a neighborhood operation. We can represent this operation by defining a subclass of \co{NeighborhoodOperation} that overrides \co{neighborhoodFunction}:
\begin{lstlisting}
public class Gray8Max extends NeighborhoodOperation {
  public int neighborhoodFunction(ImageProcessor ip, int x, int y) {
    int max = 0;
    for(int i = -1; i <= 1; i++) {
      for(int j = -1; j <= 1; j++) {
        if(ip.getPixel(x + i, y + j) > max) {
          max = ip.getPixel(x + i, y + j);          
        }
      }      
    }
    return max;
  }
}
\end{lstlisting}
This neighborhood operation can be applied to an image as follows:
\begin{lstlisting}
ImageProcessor ip = ...
NeighborhoodOperation maxNeighborhoodOperation = new Gray8Max();
maxNeighborhoodOperation.applyTo(ip);
\end{lstlisting}

\begin{exercise}
Why does the method \co{applyTo} duplicate \co{ip}?
\end{exercise}

\begin{exercise}\label{ex:gray8max}
Add the classes \co{NeighborhoodOperation} and \co{Gray8Max} to your Eclipse or Netbeans project. \texttt{lena-gray-pepper.png} is copy of \co{lena.png} with some black (pepper) noise.
\begin{center}
\includegraphics[scale=0.35]{lena-gray-pepper.png}
\end{center}
What do you expect will happen if you apply \co{Gray8Max} to this image? Check your predications. 

\texttt{lena-gray-salt.png} is copy of \co{lena.png} with some white (salt) noise. 
\begin{center}
\includegraphics[scale=0.35]{lena-gray-salt.png}
\end{center}
What do you expect will happen if you apply \co{Gray8Max} to this image? Check your predications. 
\end{exercise}

\begin{exercise}\label{ex:gray8min}
Create a new subclass of \co{NeighborhoodOperation} called \co{Gray8Min}. \co{Gray8Min} represents a neighborhood operation that replaces each pixel by the minimum color occurring in the 3x3 area around that pixel. What do you expect will happen if you apply \co{Gray8Min} to the noisy images (\texttt{lena-gray-salt.png} and \texttt{lena-gray-pepper.png})? Check your predications. 
\end{exercise}

\begin{exercise}
The size of the neighborhood is hard coded to 3x3 in the method \co{neighborhoodFunction} of \co{Gray8Min} from exercise~\ref{ex:gray8min}. Modify the class \co{Gray8Min} such that the size of the neighborhood can be passed as an argument to the constructor as follows:
\begin{itemize}
  \item Extend the class \co{Gray8Min} with two integer fields, \co{xrange} and \co{yrange}. \co{xrange} determines the width of the neighborhood and \co{yrange} its height. More specifically, the width and height of the neighborhood are respectively \co{2 * xrange + 1} and \co{2 * yrange + 1}. For example, a 3x3 neighborhood can be obtained by setting both \co{xrange} and \co{yrange} to 1. %todo: add image
  \item Add a constructor to \co{Gray8Min} that initializes \co{xrange} and \co{yrange}. 
  \item Modify the method \co{neighborhoodFunction} such that \co{xrange} and \co{yrange} determine which pixels are included in the neighborhood. 
\end{itemize}
\end{exercise}

\begin{exercise}
What is the effect of setting \co{xrange} and \co{yrange} to 0 for \texttt{lena-gray}? What about 5? What about 20?
\end{exercise}

\begin{exercise}
How does \co{Gray8Min} affect pixels near the border? Why? (Hint: Look up the behavior of \co{getPixel} in the \href{http://rsb.info.nih.gov/ij/developer/api/ij/process/ImageProcessor.html\#getPixel(int,\%20int)}{documentation of ImageProcessor}.) Modify the method \co{neighborhoodFunction} of \co{Gray8Min} such that the neighborhood of pixels near the border does not include pixels ``outside'' of the image. We will study other strategies for dealing with border pixels in Section~\ref{sec:border-pixels}.
\end{exercise}

\co{Gray8Max} eliminates the black noise from \texttt{lena-gray-pepper.png}, but it enlarges white pixels in \texttt{lena-gray-salt.png}. Similarly, \co{Gray8Min} eliminates white noise from \texttt{lena-gray-salt.png}, but enlarges black pixels in the image \texttt{lena-gray-pepper.png}. However, neither neighborhood operation removes all noise from \texttt{lena-gray-salt-and-pepper.png}. 
\begin{center}
\includegraphics[scale=0.35]{lena-gray-salt-and-pepper.png}
\end{center}
How can we remove all noise from the image shown above? Black and white noise can be removed from \texttt{lena-gray-salt-and-pepper.png} by a neighborhood operation that computes the median color occurring in the neighborhood. The median is the color that is smaller than half the pixels in the neighborhood and larger than or equal to the other half. 

\begin{exercise}
Implement a class \co{Gray8Median} that replaces each pixel by the median color occurring in the pixel's neighborhood. Find the median color by first adding each pixel in the neighborhood to an array, secondly sorting this array, and finally taking the color in the middle of that array. Note that an integer array can be sorted via the method \co{Arrays.sort}.

Check that this neighborhood operation removes both the black and white noise from \texttt{lena-gray-salt-and-pepper.png}.
\end{exercise}

\begin{exercise}
Apply \co{Gray8Median} to \texttt{mysteryperson4.png}. Who is this women hidden by salt and pepper? Hint: Apply the median neighborhood operation a number of times in a row to obtain a better image.
\end{exercise}

\begin{exercise}
A security camera has taken a picture, \co{mysterycab.png}, of a cab involved in a crime. Alas, the image quality is poor and the taxi number is not readable. Can you help out the CSI team and improve the image quality such that the taxi number becomes readable?
\end{exercise}

\section{Grayscale Linear Neighborhood Operations}
Photographing in low-light conditions or using high ISO settings can produce \emph{grainy} images. For example, the image shown below on the left was taken at ISO 100 with shutter speed 1/350s, while the image on the right was taken at ISO 1600 with shutter speed 1/4000s.
\begin{center}
\includegraphics[scale=0.22]{flower-iso-100-cropped.png}
\includegraphics[scale=0.22]{flower-iso-1600-cropped.png}
\end{center}

Notice the noise in the image on the right. The reduced shutter speed for the second image compensates for the increase in sensor sensitivity.
\begin{exercise}
\texttt{lena-gray-grainy.png} is a grainy copy of \texttt{lena.png}. Try removing the noise using \co{Gray8Median}.
\end{exercise}

We can visualize the grainy noise via a 3D surface plot\footnote{3D surface plots for grayscale images can be created in ImageJ via \texttt{Plugins>3D>Interactive 3D Surface Plot}.} as shown below. Each $(x, y, z)$ triple on the surface corresponds to a pixel at coordinate $(x, y)$ with color $z$. That is, the height of the surface represents the color of the corresponding pixels. For example, the ``peaks'' in the surfaces correspond to the bright yellow leaves of the flower, while ``valley'' correspond to the dark background.
\begin{center}
\includegraphics[scale=0.22]{flower-gray-plot.png}
\includegraphics[scale=0.22]{flower-gray-grainy-plot.png}
\end{center}
The plot corresponding to the grainy image is bumpy and not as smooth as the plot of the image taken at ISO 100. A simple way to remove the bumps in the surface (and hence the grainy noise) is to replace each pixel by the average color in the neighborhood around that pixel. Averaging is an example of \emph{blurring} (making the image less grainy, but also less sharp).

\begin{exercise}\label{ex:gray8average}
Implement a neighborhood operation called \co{Gray8Average} which replaces each pixel by the average color in the neighborhood around that pixel. As before, users of \co{Gray8Average} must be able to set the size of the neighborhood via parameters (\co{xrange} and \co{yrange}) of the constructor.

Apply \co{Gray8Average} to \texttt{flower-gray-grainy.png} for neighorhood sizes 3x3, 7x7 and 11x11 respectively. How does increasing the neighborhood size affect the 3D surface plot? 
\end{exercise}

A neighborhood operation is \emph{linear} if the new color of each pixel is a weighted sum of the pixels in its neighborhood. The term \emph{weighted} means that the color of each pixel in the neighborhood is first multiplied by a weight before adding it to the total sum. Averaging is an example of a linear neighborhood operation with weight $1/N$ for each pixel, where $N$ is the total number of pixels in the neighborhood. For example, the weight for each nearby pixel is $1/9$ if the neighborhood size is 3x3 and $1/25$ if the size is 5x5. A linear neighborhood operation is sometimes called a \co{convolution}.

Averaging uses the same weight for each pixel in the neighborhood. However, this need not be the case for all linear neighborhood operations. For example, one can increase the influence of the pixel itself on its new color and decrease the influence of the other neighbors by assigning a larger weight to the pixel itself and a smaller weight to the neighbors.

\begin{exercise}\label{ex:diffweights}
Implement a new linear neighborhood operation that replaces each pixel by a weighted sum of the pixels in the 3x3 area around that pixel. The weight of the pixel itself is $1/2$, while the other eight pixels have weight $1/16$.
\end{exercise}

Writing a new subclass of \co{NeighborhoodOperation} each time we come up with different weights is tedious. Let's write a class named \co{Convolution} where the weights of all neighbours can be passed as a matrix (two-dimensional array in Java). Such a matrix containing weights is typically called a \emph{kernel}. For example, the kernel corresponding to 3x3 averaging is the following:
$$
 \begin{bmatrix}
  \frac{1}{9} & \frac{1}{9} & \frac{1}{9} \\
  \frac{1}{9} & \textcolor{red}{\frac{1}{9}} & \frac{1}{9} \\
  \frac{1}{9} & \frac{1}{9} & \frac{1}{9}
 \end{bmatrix}
$$
The value in the center of the matrix highlighted in red is the weight corresponding to the pixel itself. The kernel corresponding to 5x5 averaging is the following:
$$
 \begin{bmatrix}
  \frac{1}{25} & \frac{1}{25} & \frac{1}{25} & \frac{1}{25} & \frac{1}{25}\\
  \frac{1}{25} & \frac{1}{25} & \frac{1}{25} & \frac{1}{25} & \frac{1}{25}\\
  \frac{1}{25} & \frac{1}{25} & \textcolor{red}{\frac{1}{25}} & \frac{1}{25} & \frac{1}{25}\\
  \frac{1}{25} & \frac{1}{25} & \frac{1}{25} & \frac{1}{25} & \frac{1}{25}\\
  \frac{1}{25} & \frac{1}{25} & \frac{1}{25} & \frac{1}{25} & \frac{1}{25}
 \end{bmatrix}
$$
Finally, the kernel corresponding to exercise~\ref{ex:diffweights} is the following:
$$
 \begin{bmatrix}
  \frac{1}{8} & \frac{1}{8} & \frac{1}{8} \\
  \frac{1}{8} & \textcolor{red}{\frac{1}{2}} & \frac{1}{8} \\
  \frac{1}{8} & \frac{1}{8} & \frac{1}{8}
 \end{bmatrix}
$$
The center of the matrix corresponding to weight of the pixel itself is sometimes called the \emph{hot spot}.

Kernels can be represented in Java as two-dimensional arrays. For example, consider the following 3x5 kernel 
$$
 \begin{bmatrix}
  \frac{1}{30} & \frac{4}{30} & \frac{1}{30} \\
  \frac{5}{30} & \frac{0}{30} & \frac{1}{30} \\
  \frac{2}{30} & \textcolor{red}{\frac{2}{30}} & \frac{2}{30}\\
  \frac{0}{30} & \frac{3}{30} & \frac{3}{30}\\
  \frac{3}{30} & \frac{0}{30} & \frac{3}{30}\\
 \end{bmatrix}
$$
This kernel is denoted in Java as follows:
\begin{lstlisting}
double[][] kernel = { { 1./30, 4./30, 1./30 },
                      { 5./30, 0./30, 1./30 },
                      { 2./30, 2./30, 2./30 },
                      { 0./30, 3./30, 3./30 },
                      { 3./30, 0./30, 3./30 } };
\end{lstlisting}
Pay attention to the following three issues when working with kernels in Java:
\begin{itemize}
  \item The rows of a two-dimensional array in Java need not have equal length. For example, the following code snippet is valid in Java:
\begin{lstlisting}
double[][] badkernel = { { 1./30, 4./30 },
                         { 5./30, 0./30, 1./30, 1./30, 1./30 },
                         { 2./30 },
                         null,
                         { 3./30, 0./30, 3./30, 1./30 } };
\end{lstlisting}
However, this two-dimensional array does not represent a valid matrix! For a two-dimensional array to be a valid matrix, all rows must be non-null and must have equal length.
  \item The weight in column $i$ and row $j$ is denoted as \co{kernel[j][i]}. So the first index represents the row number while the second one represents the column. For example, \co{kernel[1][0]} contains \co{5./30}. Note the difference with indexing in images: \co{getPixel(x, y)} returns the color of the pixel in column \co{x} and row \co{y}.
  \item In Java, \co{1/30} is not the same as \co{1./30}. The former expression evaluates to the integer \co{0}, while the latter evaluates to the double \co{0.033333333333333}.
\end{itemize}

\begin{exercise}
Create a new subclass of the class \co{NeighborhoodOperation} called \co{Convolution}.
\begin{itemize}
  \item Add a field named \co{kernel} of type \co{double[][]}. Users of the class should be able to pass the kernel as an argument to the constructor. The constructor should check that the width and height of the kernel are both odd.
  \item Implement the method \co{neighborhoodFunction} as follows:
  \begin{itemize}
    \item Create a new  local variable named \co{total} of type \co{double}. Initialize this variable to \co{0.0}.
    \item Iterate over all pixels in the neighborhood using two nested \co{for} loops. The size of the neighborhood is determined by the size of the kernel. Add the pixel's color multiplied by the appropriate weight from \co{kernel} to \co{total}.
    \item Return \co{total}.
  \end{itemize}
\end{itemize}
\end{exercise}

\begin{exercise}
Refactor the class \co{Gray8Average} from exercise \ref{ex:gray8average}.
\begin{itemize}
  \item Change the superclass of \co{Gray8Average} to \co{Convolution}.
  \item Add a new static method called \co{createAverageKernel} that returns a kernel based on two integer arguments: \co{xrange} and \co{yrange}. The width of the returned kernel is \co{2*xrange + 1} and its height is \co{2*yrange + 1}. The value of each element in the kernel is \co{1./N}, where \co{N} is the kernel's total size.
  \item The implementation of \co{Gray8Average}'s constructor should call he superclass constructor passing a kernel created by \co{createAverageKernel} as an argument.
\end{itemize}
\end{exercise}

\begin{exercise} When taking a picture of a moving subject or when shaking the camera itself, \emph{motion blur} can occur in the resulting image. For example, the moving bus in the image shown below is blurry, while the shop in the background and the phone cell in the foreground are sharp.
\begin{center}
\includegraphics[scale=0.6]{bus-motionblur.jpg}
\end{center}
Several race games artificially add motion blur to each frame to create the impression of speed. For example, the road is blurred in the screenshot of Split/Second shown below.  
\begin{center}
\includegraphics[scale=0.4]{game-motionblur.jpg}
\end{center}


Simulate horizontal motion blur in \co{ferrari-gray.png} by applying \co{Gray8Average} using a kernel with height 1 (\co{yrange} is 0) and width 41 (\co{xrange} is 20). What is the effect of increasing the kernel width?
\end{exercise}

\section{Color Linear Neighborhood Operations}

% incognito

\begin{exercise}\textbf{extra}
Bokeh is the blur in the out-of-focus area of the image. As shown in the background of the image shown below, bokeh typically manifest itself as circles or haxagons.
\begin{center}
\includegraphics[scale=0.2]{bokeh-blur.jpg}
\end{center}
The bokeh effect can be simulated by applying a linear neighborhood operation with a circular kernel.

Implement a new subclass of \co{Convolution} called \co{Bokeh}. Add a new static method called \co{createBokehKernel} with one integer parameter named \co{side}. The method generates a kernel with width and height equal to \co{side}. The value of each non-zero element in the kernel is \co{1./N}, where \co{N} is the number of non-zero elements. For example, the bokeh kernel with width and height equal to $5$ is the following:
  $$
 \begin{bmatrix}
0 & 0 & \frac{1}{13} & 0 & 0\\
0 & \frac{1}{13} & \frac{1}{13} & \frac{1}{13} & 0\\
\frac{1}{13} & \frac{1}{13} & \frac{1}{13} & \frac{1}{13} & \frac{1}{13}\\
0 & \frac{1}{13} & \frac{1}{13} & \frac{1}{13} & 0 \\
0 & 0 & \frac{1}{13} & 0 & 0 \\
 \end{bmatrix}
$$
The bokeh kernel with width and height equal to $9$ is the following:
$$
 \begin{bmatrix}
0 & 0 & 0 & 0 & \frac{1}{49} & 0 & 0 & 0 & 0\\
0 & 0 & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & 0 & 0\\
0 & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & 0\\
0 & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & 0\\
\frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49}\\
0 & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & 0\\
0 & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & 0\\
0 & 0 & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & \frac{1}{49} & 0 & 0\\
0 & 0 & 0 & 0 & \frac{1}{49} & 0 & 0 & 0 & 0\\
 \end{bmatrix}
$$
In a bokeh kernels shown above, an element is non-zero only if its distance to the center is smaller than the kernel width. The distance between two 2D points $(x_1, y_1)$ and $(x_2, y_2)$ can be computed using the following formula:
$$\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$$
Create a bokeh kernel with width and height 51 and convolve \co{christmastree-gray.png} using this kernel.
\end{exercise}

\section{Gaussian Blurring}
Averaging is often referred to as a \emph{box filter} because the shape of its kernel resembles a box.
\begin{center}
\includegraphics[scale=0.3]{boxfilter.png}
\end{center}
The height of each box element is $1/N$, where $N$ is the size of the neighborhood.

Blurring via a box filter has two important disadvantages. First of all, a box filter is not \emph{isotropic} meaning that the kernel is not uniform in all directions. Informally, a kernel is isotropic if it looks the same from all sides. Secondly, a box kernel assigns equal weights to all pixels in the neighborhood. However, it is often preferable to have stronger emphasis given to pixels near the center of the kernel than to more distant ones. For these reasons, the default blur (or smooth) command in most image editing programs using a gaussian kernel instead of a box kernel.

Gaussian blurring uses a kernel based on the gauss function.
\begin{center}
\includegraphics[scale=0.3]{gaussfilter.png}
\end{center}
The gauss kernel is isotropic. Moreover, the weight of each element depends on its distance from the hot spot (i.e. the center of the matrix).

How can we construct such a Gauss kernel? Before we answer this question, let's study the 1-dimensional gauss function. The 1-dimensional function $g_\sigma$ is defined as follows:
$$g_\sigma(x) = \frac{1}{\sigma\sqrt{2\pi}} \cdot e^{-\frac{x^2}{2\sigma^2}}$$
where $\sigma$ denotes the with (standard deviation) of the bell-shaped function and $e$ is Euler's number ($2.7182$). The plot shown below depicts the gauss function within the range $-5$ to $5$ for $\sigma$ equal to 1, 2 and 3.

\begin{center}
\includegraphics[scale=0.4]{gaussplot.pdf}
\end{center}

The domain of $g_\sigma$ is $\mathbb{R}$. This means that the function has a value for each possible value of $x$. However, the value of $g_\sigma(x)$ approaches zero as $|x|$ grows. In particular, $g_\sigma(x) \approx 0$ if $|x| > 3\sigma$. For example in the plot shown above $g_\sigma$ approaches zero for $\sigma$ equal to 1 when $x > 3$ or $x < 3$.  

\begin{exercise}
Implement the 1-dimensional gauss function in Java as a static method:
\begin{lstlisting}
public static double gauss1d(double x, double sigma) {
  ...
}
\end{lstlisting}
Euler's number is denoted in Java as \co{Math.E}.
\end{exercise}

The 2-dimensional gauss function $G_\sigma$ is defined as follows:
$$G_\sigma(x, y) = g_\sigma(x) \cdot g_\sigma(y)$$
The value of $G_\sigma(x, y)$ approaches zero as $|x|$ and $|y|$ grow. Based on the 2-dimensional gauss function $G_\sigma$, we can construct a kernel as follows:
$$
\begin{bmatrix}
\dots & \dots & \dots & \dots & \dots & \dots & \dots\\
\dots & G(-2, -2) & G(-1, -2) & G(0, -2) & G(1, -2) & G(2, -2) & \dots\\
\dots & G(-2, -1) & G(-1, -1) & G(0, -1) & G(1, -1) & G(2, -1) & \dots\\
\dots & G(-2, 0) & G(-1, 0) & G(0, 0) & G(1, 0) & G(2, 0) & \dots\\
\dots & G(-2, 1) & G(-1, 1) & G(0, 1) & G(1, 1) & G(2, 1) & \dots\\
\dots & G(-2, 2) & G(-1, 2) & G(0, 2) & G(1, 2) & G(2, 2) & \dots\\
\dots & \dots & \dots & \dots & \dots & \dots & \dots\\
\end{bmatrix}
$$
The domain $G_\sigma$ is $\mathbb{R} \times \mathbb{R}$. What the size of the kernel? Because the value of $G_\sigma(x, y)$ is close to zero when $|x| > 3\sigma$ or $|y| > 3\sigma$, \co{xrange} and \co{yrange} are typically set to $3\sigma$ or even $2.5\sigma$ (rounded down). In the remainder of this section, we select the latter option, $2.5\sigma$. Thus, if $\sigma$ equals 1, the gauss kernel is 5 by 5:
$$
\begin{bmatrix}
0.0029 & 0.0131 & 0.0215 & 0.0131 & 0.0029\\
0.0131 & 0.0585 & 0.0965 & 0.0585 & 0.0131\\
0.0215 & 0.0965 & 0.1592 & 0.0965 & 0.0215\\
0.0131 & 0.0585 & 0.0965 & 0.0585 & 0.0131\\
0.0029 & 0.0131 & 0.0215 & 0.0131 & 0.0029\\
\end{bmatrix}
$$
Similarly, if $\sigma$ equals 2, the gauss kernel is 11 by 11:
{\footnotesize{$$
\begin{bmatrix}
0.0001 & 0.0002 & 0.0006 & 0.0011 & 0.0015 & 0.0017 & 0.0015 & 0.0011 & 0.0006 & 0.0002 & 0.0001\\
0.0002 & 0.0007 & 0.0017 & 0.0033 & 0.0048 & 0.0054 & 0.0048 & 0.0033 & 0.0017 & 0.0007 & 0.0002\\
0.0006 & 0.0017 & 0.0042 & 0.0078 & 0.0114 & 0.0129 & 0.0114 & 0.0078 & 0.0042 & 0.0017 & 0.0006\\
0.0011 & 0.0033 & 0.0078 & 0.0146 & 0.0213 & 0.0241 & 0.0213 & 0.0146 & 0.0078 & 0.0033 & 0.0011\\
0.0015 & 0.0048 & 0.0114 & 0.0213 & 0.0310 & 0.0351 & 0.0310 & 0.0213 & 0.0114 & 0.0048 & 0.0015\\
0.0017 & 0.0054 & 0.0129 & 0.0241 & 0.0351 & 0.0398 & 0.0351 & 0.0241 & 0.0129 & 0.0054 & 0.0017\\
0.0015 & 0.0048 & 0.0114 & 0.0213 & 0.0310 & 0.0351 & 0.0310 & 0.0213 & 0.0114 & 0.0048 & 0.0015\\
0.0011 & 0.0033 & 0.0078 & 0.0146 & 0.0213 & 0.0241 & 0.0213 & 0.0146 & 0.0078 & 0.0033 & 0.0011\\
0.0006 & 0.0017 & 0.0042 & 0.0078 & 0.0114 & 0.0129 & 0.0114 & 0.0078 & 0.0042 & 0.0017 & 0.0006\\
0.0002 & 0.0007 & 0.0017 & 0.0033 & 0.0048 & 0.0054 & 0.0048 & 0.0033 & 0.0017 & 0.0007 & 0.0002\\
0.0001 & 0.0002 & 0.0006 & 0.0011 & 0.0015 & 0.0017 & 0.0015 & 0.0011 & 0.0006 & 0.0002 & 0.0001\\
\end{bmatrix}
$$}}

\begin{exercise}
Implement gaussian blurring in the class \co{GaussianBlur}, a new subclass of \co{Convolution}.
\begin{itemize}
  \item  Add a static method called \co{createGaussKernel} with one double parameter named \co{sigma}. The method creates a kernel based on the given \co{sigma}.
  \item The constructor of \co{GaussianBlur} takes \co{sigma} as an argument. The \co{super} call should take \co{createGaussKernel} as an argument.
\end{itemize}
\end{exercise}

\begin{exercise}
Google street view is an extension of Google maps that provides panoramic views from positions along many streets in the world. To address privacy concerns, users can ask Google to make certain images unrecognisable. Google does so by applying a blur filter. For example, \href{http://maps.google.be/?ll=50.86546,4.700148&spn=0.0014,0.00246&t=m&layer=c&cbll=50.865564,4.700181&panoid=2s4kQDqWdj96P1mRHbEahQ&cbp=12,229.38,,0,-4.81&z=19}{some images taken in the Burgemeester Jozef Eerdekensstraat in Leuven} were blurred in Google street view.

\co{khl-streetview-gray.png} is a Google street view image taken at the Department of Health and Technology of the KHLeuven. Apply a gaussian blur to this image. What is the required value of $\sigma$ to make the text on the banner illegible.  
\end{exercise}

%\begin{exercise}
%Open \co{larg
%Apply gaussian blurring with $\sigma$ equal to $20$ to \texttt{largeimage.png}. How many seconds does this take? How many pixels are examined for each individual pixel?
%\end{exercise}

\subsection{Normalization}

\begin{exercise}
\texttt{whiteimage.png} is an image containing only perfectly white pixels (color = 255). What do you expect will happen if you apply gaussian blurring to this image? Will the pixels (in the center of the image) remain perfectly white? Why or why not? Check your predictions? 
\end{exercise}

The total sum of the weights in the gauss kernels shown above is not exactly 1, but 0.98 (why?). This means that an image will not only be blurred, but also become slightly darker. This undesirable side effect can be prevented by \emph{normalising} the kernel, i.e. by dividing each element in the kernel by the total sum. After normalisation the total sum of the weights equals 1.   

\begin{exercise}
Add a method \co{normalise} to the class \co{Convolution}. Again apply gaussian blurring to \texttt{whiteimage.png}, but normalize the kernel this time. What do you see? 
\end{exercise}

% separable
% unsharp mask

\subsection{Separability}

\begin{exercise}
Apply gaussian blurring with $\sigma$ equal to 10 to \texttt{earth-gray.png}. How many seconds does this take? How many pixels are examined for determining the new value of each pixel?
\end{exercise}

The size of the kernel determines the number of pixels taken into account when computing the new color of each individual pixel. For example, the size of the gaussian blur kernel for $\sigma$ equal to 10 is 51 by 51. This means that for each pixel 2601 (=$51^2$) other pixels are examined. Such a convolution is computationally intensive.

Luckily, some kernels (such as a gaussian one) are \emph{separable}. This means that one can replace a convolution with a large, square matrix by two one-dimensional convolutions.  

\begin{exercise}
Exploit the separability of the gauss kernel to implement fast gaussian blurring. Apply fast gaussian blurring with $\sigma$ equal to 10 to \texttt{earth-gray.png}. How many seconds does this take? How many pixels are examined for determining the new value of each pixel?
\end{exercise}


% lens blur
% blurring color images
% cartoon style
% noise removal with edge preservation
% ...

% applications: blurring incognito, noise removal (e.g. preprocessing to edge detection), transitions, unsharp mask, focus on foreground subject 

\section{Dealing with Border Pixels}\label{sec:border-pixels}

%transition


\end{document}

